mymcp-prompt

I would like to build an application that can operate both by itself/standalone and function within a larger framework that will be composed of multiple standalone modules connected to a "hub" module that contains the "project manager" and "editor" agents to orchestrate the use of all the modules, assess the quality of the output, and organize the response to the user/prompter. We will module "MyMCP". MyMCP will, from a user prompt, create MCP server(s)*.

Like I mentioned at the beginning, this should appear to be a complete and finished work by itself. However, this module should be able to be (or at least appear to be) dropped into a larger set of similar applications. When this set of similar applications, however many there are, should be able to unlock both the function of the standalone module, but also a teamwork function that adds something of significance to the combined application. I would like this to be a full stack application that could be easily ted as a module for a larger application that uses Python as the backend and utilizes a knowledge graph based RAG data store strategy. The knowledge graph RAG system will likely be SimRAG and/or LightRAG order to as fully as possible leverage the power of multi-layer knowledge graph (e.g. contextual and semantic searches on multiple levels to connect many separate subject matter knowledge graphs in one database). Therefore this MCP server, tool, and prompt application, named MyMCP, will need to be built to be able to function on its own (stand alone), but also integrated into a larger framework that utilizes a multi knowledge graph RAG database to which and from which to add and retrieve data for the purpose of LLM function calling and, potentially siloed, domain specific data.

Notes:
*```MCP server


Use case examples:
1) an individual78:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/20258:15 AM 1/10/2025 builds a personal data store of their information. From that information they wish to use their financial, health, and other personal information to build tool	edrs, MCP servers, and/or agents to handle tasks for them. This module will handle accepting that person's prompt and generating the MCP server, function call/tool, and agent prompt code (JSON, Typescript, Python, etc.)
another use case might be 



(1) the left menu pane should have a drop down of different LLM APIs that are built into the application. Initially, I would like for OpenAI, Anthropic, Google, Groq, SombaNova, Cerebras, OpenRouter, Ollama, and LM Studio to be options built into the application from launch.

, tool(s) in Python for function calling**, and a prompt that can be used in an agent builder framework like Autogen and CrewAI to build custom AI Agents***. 